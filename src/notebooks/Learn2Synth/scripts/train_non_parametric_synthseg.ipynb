{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13643074,"sourceType":"datasetVersion","datasetId":8672484},{"sourceId":14002138,"sourceType":"datasetVersion","datasetId":8921751}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Implement Learn2Synth","metadata":{}},{"cell_type":"markdown","source":"## 1. Environment Setup","metadata":{}},{"cell_type":"code","source":"# 1. Install Cornucopia (if not already present)\n!pip install git+https://github.com/balbasty/cornucopia@6f8ab58dfcfe8978c9aa9e8b05898dcf7d75bb5b\n\n# 2. CRITICAL FIX: Force reinstall compatible Torch, Torchvision, and Numpy\n# This aligns torchvision (0.21.0) with torch (2.6.0) and fixes the NMS error.\n!pip install \"torch==2.6.0+cu124\" \"torchvision==0.21.0+cu124\" \"torchaudio==2.6.0+cu124\" --index-url https://download.pytorch.org/whl/cu124\n\n# 3. Ensure Numpy is version 1.x (fixes the _ARRAY_API error)\n!pip install \"numpy<2.0\"\n\n!pip install -U \"jsonargparse[signatures]>=4.27.7\"\n!pip install \"protobuf==3.20.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:32:34.832747Z","iopub.execute_input":"2025-12-05T05:32:34.833270Z","iopub.status.idle":"2025-12-05T05:34:01.538922Z","shell.execute_reply.started":"2025-12-05T05:32:34.833247Z","shell.execute_reply":"2025-12-05T05:34:01.538192Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/balbasty/cornucopia@6f8ab58dfcfe8978c9aa9e8b05898dcf7d75bb5b\n  Cloning https://github.com/balbasty/cornucopia (to revision 6f8ab58dfcfe8978c9aa9e8b05898dcf7d75bb5b) to /tmp/pip-req-build-04w3ous5\n  Running command git clone --filter=blob:none --quiet https://github.com/balbasty/cornucopia /tmp/pip-req-build-04w3ous5\n  Running command git rev-parse -q --verify 'sha^6f8ab58dfcfe8978c9aa9e8b05898dcf7d75bb5b'\n  Running command git fetch -q https://github.com/balbasty/cornucopia 6f8ab58dfcfe8978c9aa9e8b05898dcf7d75bb5b\n  Running command git checkout -q 6f8ab58dfcfe8978c9aa9e8b05898dcf7d75bb5b\n  Resolved https://github.com/balbasty/cornucopia to commit 6f8ab58dfcfe8978c9aa9e8b05898dcf7d75bb5b\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from cornucopia==0.4.0) (2.6.0+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cornucopia==0.4.0) (1.26.4)\nRequirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from cornucopia==0.4.0) (5.3.2)\nCollecting torch-interpol>=0.2.4 (from cornucopia==0.4.0)\n  Downloading torch_interpol-0.2.6-py3-none-any.whl.metadata (9.1 kB)\nCollecting torch-distmap (from cornucopia==0.4.0)\n  Downloading torch_distmap-0.2.0-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->cornucopia==0.4.0) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->cornucopia==0.4.0) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->cornucopia==0.4.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->cornucopia==0.4.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->cornucopia==0.4.0) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->cornucopia==0.4.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->cornucopia==0.4.0)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->cornucopia==0.4.0)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->cornucopia==0.4.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->cornucopia==0.4.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->cornucopia==0.4.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->cornucopia==0.4.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->cornucopia==0.4.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->cornucopia==0.4.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->cornucopia==0.4.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->cornucopia==0.4.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->cornucopia==0.4.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->cornucopia==0.4.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->cornucopia==0.4.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->cornucopia==0.4.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->cornucopia==0.4.0) (1.3.0)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->cornucopia==0.4.0) (6.5.2)\nRequirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel->cornucopia==0.4.0) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->cornucopia==0.4.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->cornucopia==0.4.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->cornucopia==0.4.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->cornucopia==0.4.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->cornucopia==0.4.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->cornucopia==0.4.0) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->cornucopia==0.4.0) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->cornucopia==0.4.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->cornucopia==0.4.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->cornucopia==0.4.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->cornucopia==0.4.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->cornucopia==0.4.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->cornucopia==0.4.0) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torch_interpol-0.2.6-py3-none-any.whl (37 kB)\nDownloading torch_distmap-0.2.0-py3-none-any.whl (12 kB)\nBuilding wheels for collected packages: cornucopia\n  Building wheel for cornucopia (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for cornucopia: filename=cornucopia-0.4.0-py3-none-any.whl size=126230 sha256=d57da78ad09e870011b2af1930120d151825501ea7750abeb410eea11b68c22e\n  Stored in directory: /root/.cache/pip/wheels/7d/42/ee/cf2ecf2eae2764c47f2c556674f51eb480437e8a8be2157a6c\nSuccessfully built cornucopia\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-interpol, torch-distmap, cornucopia\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cornucopia-0.4.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-distmap-0.2.0 torch-interpol-0.2.6\nLooking in indexes: https://download.pytorch.org/whl/cu124\nRequirement already satisfied: torch==2.6.0+cu124 in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision==0.21.0+cu124 in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: torchaudio==2.6.0+cu124 in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (1.13.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0+cu124) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0+cu124) (11.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0+cu124) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0+cu124) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.21.0+cu124) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 2. Package Setup","metadata":{}},{"cell_type":"code","source":"# Cell 2: Setup learn2synth package\nimport os\nimport shutil\n\n# Paths\nINPUT_SOURCE = \"/kaggle/input/learn2synth-sourcecode/learn2synth\"\nWORKING_DIR = \"/kaggle/working\"\nPACKAGE_DIR = os.path.join(WORKING_DIR, \"learn2synth\")\nSCRIPT_DIR = os.path.join(WORKING_DIR, \"scripts\")\n\n# Create package folder\nos.makedirs(PACKAGE_DIR, exist_ok=True)\nos.makedirs(SCRIPT_DIR, exist_ok=True)\n\n# Copy python files\nfor filename in os.listdir(INPUT_SOURCE):\n    if filename.endswith(\".py\"):\n        shutil.copyfile(os.path.join(INPUT_SOURCE, filename), os.path.join(PACKAGE_DIR, filename))\n\n# Ensure it's a package\nif not os.path.exists(os.path.join(PACKAGE_DIR, \"__init__.py\")):\n    open(os.path.join(PACKAGE_DIR, \"__init__.py\"), 'a').close()\n\nprint(\"Library setup complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:34:01.540611Z","iopub.execute_input":"2025-12-05T05:34:01.540867Z","iopub.status.idle":"2025-12-05T05:34:01.587324Z","shell.execute_reply.started":"2025-12-05T05:34:01.540842Z","shell.execute_reply":"2025-12-05T05:34:01.586561Z"}},"outputs":[{"name":"stdout","text":"Library setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 3. Define Training Script","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Imports and Configuration","metadata":{}},{"cell_type":"code","source":"%%writefile scripts/train_non_parametric_synthseg.py\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.cli import LightningCLI\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nimport sys\nimport os\nfrom glob import glob\nfrom os import path, makedirs\nfrom ast import literal_eval\nfrom random import shuffle\nfrom typing import Sequence, List, Tuple, Optional, Union\nimport math\nimport fnmatch\nimport random\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport nibabel as nib\nimport cornucopia as cc\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics.segmentation import DiceScore as dice_compute\n\n# --- Project Imports ---\n# Ensure this points to the correct location of your 'learn2synth' folder\nproject_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.append(project_root)\n\nfrom learn2synth.networks import UNet, SegNet\nfrom learn2synth.train import SynthSeg\nfrom learn2synth.losses import DiceLoss, LogitMSELoss, CatLoss, CatMSELoss\nfrom learn2synth import optim\nfrom cornucopia import SynthFromLabelTransform, LoadTransform\nfrom learn2synth.utils import folder2files\n\n# --- Configuration ---\n# Pointing to your Kaggle dataset structure\nDEFAULT_FOLDER = '/kaggle/input/wmh-synthseg-dataset'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:34:01.588130Z","iopub.execute_input":"2025-12-05T05:34:01.588373Z","iopub.status.idle":"2025-12-05T05:34:01.594026Z","shell.execute_reply.started":"2025-12-05T05:34:01.588354Z","shell.execute_reply":"2025-12-05T05:34:01.593313Z"}},"outputs":[{"name":"stdout","text":"Writing scripts/train_non_parametric_synthseg.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 3.2 Model Architecture","metadata":{}},{"cell_type":"code","source":"%%writefile -a scripts/train_non_parametric_synthseg.py\n\nclass Model(pl.LightningModule):\n    def __init__(self,\n                 ndim: int = 3,\n                 nb_classes: int = 2,  # 0=Background, 1=FCD\n                 seg_nb_levels: int = 6,\n                 seg_features: Sequence[int] = (16, 32, 64, 128, 256, 512),\n                 seg_activation: str = 'ReLU',\n                 seg_nb_conv: int = 2,\n                 seg_norm: Optional[str] = 'instance',\n                 loss: str = 'dice',\n                 alpha: float = 1.0,\n                 # Parameters for the \"Real\" logging branch (optional visualization)\n                 real_sigma_min: float = 0.15,\n                 real_sigma_max: float = 0.15,\n                 real_low: float = 0.5,\n                 real_middle: float = 0.5,\n                 real_high: float = 0.5,\n                 classic: bool = True,\n                 optimizer: str = 'Adam',\n                 optimizer_options: dict = dict(lr=1e-4),\n                 ):\n        super().__init__()\n        self.save_hyperparameters()\n\n        self.optimizer = optimizer\n        self.optimizer_options = dict(optimizer_options or {})\n        self.alpha = alpha\n        \n        # Real image augmentation params (for validation visualization only)\n        self.real_sigma_min = real_sigma_min\n        self.real_sigma_max = real_sigma_max\n        self.real_low = real_low\n        self.real_middle = real_middle\n        self.real_high = real_high\n        self.classic = classic\n\n        # --- 1. Segmentation Network (The Student) ---\n        segnet = UNet(\n            ndim,\n            features=seg_features,\n            activation=seg_activation,\n            nb_levels=seg_nb_levels,\n            nb_conv=seg_nb_conv,\n            norm=seg_norm,\n        )\n        segnet = SegNet(ndim, 1, nb_classes, backbone=segnet, activation=None)\n\n        # --- 2. Target Labels ---\n        # Note: If you want to force the model to distinguish FCD from normal cortex,\n        # consider adding the cortex label here (e.g. `(3,)`) and increasing nb_classes.\n        target_labels = [\n            (99,),  # Label 1: Focal Cortical Dysplasia (The Legion)\n        ]\n\n        # --- 3. Synthesis Generator (The Teacher) ---\n        synth = cc.SynthFromLabelTransform(\n            # A. Label Handling\n            one_hot=False,          # Return integer map [0, 1]\n            target_labels=target_labels, \n            \n            # B. Geometric Deformations (Crucial for Cortical Thickening)\n            elastic=0.05,           # Strong elastic deformation to change thickness\n            elastic_nodes=10,       # Wavy deformations\n            rotation=15,            # +/- 15 degrees\n            shears=0.012,\n            zooms=0.15,\n\n            # C. MRI Simulation (Crucial for FCD Subtlety)\n            resolution=5,           # [0-5x] downsampling. Simulates partial volume / blurring at GW junction.\n            motion_fwhm=2.0,        # [0-2mm] blur. Simulates \"fuzzy\" borders characteristic of FCD.\n            snr=10,                 # Low SNR. Hides the lesion in noise so strict intensity isn't enough.\n            gmm_fwhm=10,            # High texture smoothing. Makes lesion look like a cohesive tissue block.\n            gamma=0.5,              # Aggressive contrast scrambling. Forces learning shape over brightness.\n            \n            # D. Artifacts\n            bias=7,                 # Smooth bias field\n            bias_strength=0.5,      # Strong intensity inhomogeneity\n        )\n\n        # Wrap in SharedSynth to ensure Real validation images get same geometric warp\n        synth = cc.batch(SharedSynth(synth))\n\n        # --- 4. Loss Function ---\n        if loss == 'dice':\n            # Softmax needed because output is [B, 2, H, W, D]\n            loss = DiceLoss(activation='Softmax')\n        elif loss == 'logitmse':\n            loss = LogitMSELoss()\n        elif loss == 'cat':\n            loss = CatLoss(activation='Softmax')\n        elif loss == 'catmse':\n            loss = CatMSELoss(activation='Softmax')\n        else:\n            raise ValueError('Unsupported loss', loss)\n\n        self.network = SynthSeg(segnet, synth, loss)\n\n        # Manual optimization control (required for Learn2Synth/SynthSeg framework)\n        self.automatic_optimization = False\n        self.network.set_backward(self.manual_backward)\n\n    def configure_optimizers(self):\n        optimizer = getattr(optim, self.optimizer)\n        optimizer_init = lambda x: optimizer(x, **(self.optimizer_options or {}))\n        optimizers = self.network.configure_optimizers(optimizer_init)\n        self.network.set_optimizers(self.optimizers)\n        return optimizers\n\n    def training_step(self, batch, batch_idx):\n        if self.trainer.current_epoch % 10 == 0 and batch_idx == 0:\n            torch.cuda.empty_cache()\n\n        # loss_real is calculated but detached (no gradient)\n        loss_synth, loss_real = self.network.synth_and_train_step(*batch)\n        \n        # Combined for logging purposes only\n        loss = loss_synth + self.alpha * loss_real\n        \n        self.log(f'train_loss', loss, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        dice_real = 0\n\n        # Plot/Log images for the first batch of the epoch\n        if batch_idx == 0:\n            root = f'{self.logger.log_dir}/images'\n            makedirs(root, exist_ok=True)\n            epoch = self.trainer.current_epoch\n\n            loss_synth, loss_real, pred_synth, pred_real, \\\n                synth_image, synth_ref, real_image, real_ref \\\n                = self.network.synth_and_eval_for_plot(*batch)\n\n            # --- Compute Metrics on Real Data ---\n            # input_format=\"index\" means inputs are integer class labels, not one-hot\n            dice_score = dice_compute(average='micro', include_background=False, \n                                    num_classes=2, input_format=\"index\")\n\n            pred_real = pred_real.cpu()\n            real_ref = real_ref.cpu()\n\n            # [B, C, X, Y, Z] -> [B, X, Y, Z] (Integer labels)\n            pred_labels = pred_real.argmax(dim=1)\n            target_labels = real_ref.squeeze(1)\n\n            dice_score.update(pred_labels, target_labels)\n            dice_real = dice_score.compute()\n\n            self.log('dice_real', dice_real, prog_bar=True)\n\n            # Save NIfTI files for visual inspection\n            if epoch % 10 == 0:\n                pred_synth_argmax = pred_synth[0].argmax(dim=0)\n                pred_real_argmax = pred_real[0].argmax(dim=0)\n                \n                save(pred_synth_argmax, f'{root}/epoch-{epoch:04d}_synth-pred.nii')\n                save(pred_real_argmax, f'{root}/epoch-{epoch:04d}_real-pred.nii')\n                save(synth_image[0].squeeze(0), f'{root}/epoch-{epoch:04d}_synth-image.nii')\n                save(real_image[0].squeeze(0), f'{root}/epoch-{epoch:04d}_real-image.nii')\n                # Cast refs to uint8 for label saving\n                save(synth_ref[0].squeeze(0).to(torch.uint8), f'{root}/epoch-{epoch:04d}_synth-ref.nii')\n                save(real_ref[0].squeeze(0).to(torch.uint8), f'{root}/epoch-{epoch:04d}_real-ref.nii')\n        else:\n            loss_synth, loss_real = self.network.synth_and_eval_step(*batch)\n\n        loss = loss_synth + self.alpha * loss_real\n        self.log('eval_loss', loss)\n        return loss\n\n    def forward(self, x):\n        return self.network(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:34:01.595706Z","iopub.execute_input":"2025-12-05T05:34:01.595900Z","iopub.status.idle":"2025-12-05T05:34:01.614133Z","shell.execute_reply.started":"2025-12-05T05:34:01.595883Z","shell.execute_reply":"2025-12-05T05:34:01.613405Z"}},"outputs":[{"name":"stdout","text":"Appending to scripts/train_non_parametric_synthseg.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### 3.3 Helper Functions","metadata":{}},{"cell_type":"code","source":"%%writefile -a scripts/train_non_parametric_synthseg.py\n\ndef save(dat, fname):\n    dat = dat.detach().cpu().numpy()\n    h = nib.Nifti1Header()\n    h.set_data_dtype(dat.dtype)\n    nib.save(nib.Nifti1Image(dat, np.eye(4), h), fname)\n\n\nclass SharedSynth(torch.nn.Module):\n    \"\"\"\n    Wrapper that applies the exact same geometric deformation to both \n    the Synthetic branch (generation) and the Real branch (augmentation).\n    \"\"\"\n    def __init__(self, synth):\n        super().__init__()\n        self.synth = synth\n\n    def forward(self, slab, img, lab):\n        # 1. Sample random parameters based on the label map 'slab'\n        final = self.synth.make_final(slab, 1)\n        final.deform = final.deform.make_final(slab)\n        \n        # 2. Generate Synthetic Image\n        simg, slab = final(slab)\n        \n        # 3. Apply SAME deformation to Real Image\n        rimg, rlab = final.deform([img, lab])\n        rimg = final.intensity(rimg)\n        rlab = final.postproc(rlab)\n        \n        return simg, slab, rimg, rlab\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:34:01.615014Z","iopub.execute_input":"2025-12-05T05:34:01.615497Z","iopub.status.idle":"2025-12-05T05:34:01.630085Z","shell.execute_reply.started":"2025-12-05T05:34:01.615475Z","shell.execute_reply":"2025-12-05T05:34:01.629528Z"}},"outputs":[{"name":"stdout","text":"Appending to scripts/train_non_parametric_synthseg.py\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### 3.4 Data Loading","metadata":{}},{"cell_type":"code","source":"%%writefile -a scripts/train_non_parametric_synthseg.py\n\nclass PairedDataset(Dataset):\n    def __init__(self, ndim, images, labels, split_synth_real=True,\n                 subset=None, device=None):\n        self.ndim = ndim\n        self.device = device\n        self.split_synth_real = split_synth_real\n        self.labels = np.asarray(folder2files(labels)[subset or slice(None)])\n        self.images = np.asarray(folder2files(images)[subset or slice(None)])\n        \n        assert len(self.labels) == len(self.images), \\\n            \"Number of labels and images don't match\"\n\n    def __len__(self):\n        n = len(self.images)\n        if self.split_synth_real:\n            n = n // 2\n        return n\n\n    def __getitem__(self, idx):\n        # Load Real Label and Real Image\n        lab = str(self.labels[idx])\n        img = str(self.images[idx])\n\n        lab = LoadTransform(ndim=self.ndim, dtype=torch.long, device=self.device)(lab)\n        img = LoadTransform(ndim=self.ndim, dtype=torch.float32, device=self.device)(img)\n\n        if self.split_synth_real:\n            # If split, use a DIFFERENT label map for synthesis than for validation\n            slab = str(self.labels[len(self) + idx])\n            slab = LoadTransform(ndim=self.ndim, dtype=torch.long, device=self.device)(slab)\n            return slab, img, lab\n        else:\n            # Shared: Use the SAME label map for synthesis and validation\n            return lab, img, lab\n\n\nclass PairedDataModule(pl.LightningDataModule):\n    def __init__(self,\n                 ndim: int,\n                 images: Optional[Sequence[str]] = None,\n                 labels: Optional[Sequence[str]] = None,\n                 eval: Union[str, slice, List[int], int, float] = 0.2,\n                 test: Union[str, slice, List[int], int, float] = 0.2,\n                 preshuffle: bool = True,\n                 shared: bool = False,\n                 batch_size: int = 64,\n                 shuffle: bool = False,\n                 num_workers: int = 4,\n                 prefetch_factor: int = 2,\n                 ):\n        super().__init__()\n        self.ndim = ndim\n\n        # --- DATA LOADING ---\n        if labels is None or images is None:\n            # Search for sub-XXXX folders\n            subject_folders = sorted(glob(path.join(DEFAULT_FOLDER, 'sub-*')))\n            self.labels = []\n            self.images = []\n\n            print(f\"Found {len(subject_folders)} subject folders. Scanning...\")\n\n            for subj_dir in subject_folders:\n                # Pair FusedMask (Label) with FLAIR (Image)\n                label_path = path.join(subj_dir, 'FusedMask.nii')\n                image_path = path.join(subj_dir, 'FLAIR.nii')\n\n                if path.exists(label_path) and path.exists(image_path):\n                    self.labels.append(label_path)\n                    self.images.append(image_path)\n            \n            print(f\"Successfully loaded {len(self.labels)} pairs.\")\n        else:\n            self.labels = list(labels)\n            self.images = list(images)\n\n        assert len(self.images) == len(self.labels), \"Mismatch in file counts!\"\n\n        self.eval = parse_eval(eval)\n        self.test = parse_eval(test)\n        self.preshuffle = preshuffle\n        self.shared = shared\n        self.train_kwargs = dict(batch_size=batch_size, shuffle=shuffle, \n                               num_workers=num_workers, prefetch_factor=prefetch_factor)\n        self.eval_kwargs = dict(batch_size=batch_size, shuffle=False, \n                               num_workers=num_workers, prefetch_factor=prefetch_factor)\n\n    def setup(self, stage):\n        images, labels = self.images, self.labels\n        \n        if self.preshuffle:\n            combined = list(zip(images, labels))\n            shuffle(combined)\n            images, labels = zip(*combined)\n            images, labels = list(images), list(labels)\n\n        # Calculate split indices\n        def get_count(param, total):\n            if isinstance(param, float): return int(math.ceil(total * param))\n            return 0 # Default fallback\n\n        n_eval = get_count(self.eval, len(images))\n        n_test = get_count(self.test, len(images))\n\n        # Split: Test -> Eval -> Train\n        self.test_images, self.test_labels = images[:n_test], labels[:n_test]\n        remaining_images = images[n_test:]\n        remaining_labels = labels[n_test:]\n        \n        self.eval_images, self.eval_labels = remaining_images[:n_eval], remaining_labels[:n_eval]\n        self.train_images, self.train_labels = remaining_images[n_eval:], remaining_labels[n_eval:]\n\n    def train_dataloader(self):\n        return DataLoader(PairedDataset(self.ndim, self.train_images, self.train_labels, \n                                      split_synth_real=not self.shared), **self.train_kwargs)\n\n    def val_dataloader(self):\n        return DataLoader(PairedDataset(self.ndim, self.eval_images, self.eval_labels, \n                                      split_synth_real=not self.shared), **self.eval_kwargs)\n\n    def test_dataloader(self):\n        return DataLoader(PairedDataset(self.ndim, self.test_images, self.test_labels, \n                                      split_synth_real=not self.shared), **self.eval_kwargs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:34:01.630870Z","iopub.execute_input":"2025-12-05T05:34:01.631212Z","iopub.status.idle":"2025-12-05T05:34:01.647267Z","shell.execute_reply.started":"2025-12-05T05:34:01.631184Z","shell.execute_reply":"2025-12-05T05:34:01.646581Z"}},"outputs":[{"name":"stdout","text":"Appending to scripts/train_non_parametric_synthseg.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### 3.5 Main Execution","metadata":{}},{"cell_type":"code","source":"%%writefile -a scripts/train_non_parametric_synthseg.py\n\ndef parse_eval(eval):\n    if not isinstance(eval, str): return eval\n    try: return literal_eval(eval)\n    except: return eval\n\nclass CLI(LightningCLI):\n    def add_arguments_to_parser(self, parser):\n        parser.add_lightning_class_args(ModelCheckpoint, \"checkpoint\")\n        parser.set_defaults({\n            \"checkpoint.monitor\": \"eval_loss\",\n            \"checkpoint.save_last\": True,\n            \"checkpoint.save_top_k\": 5,\n            \"checkpoint.every_n_epochs\": 10,\n        })\n\nif __name__ == '__main__':\n    cli = CLI(Model, PairedDataModule)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:34:01.648007Z","iopub.execute_input":"2025-12-05T05:34:01.648302Z","iopub.status.idle":"2025-12-05T05:34:01.664522Z","shell.execute_reply.started":"2025-12-05T05:34:01.648274Z","shell.execute_reply":"2025-12-05T05:34:01.663884Z"}},"outputs":[{"name":"stdout","text":"Appending to scripts/train_non_parametric_synthseg.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 4. Run Training","metadata":{}},{"cell_type":"code","source":"!python /kaggle/working/scripts/train_non_parametric_synthseg.py fit \\\n    --data.ndim 3 \\\n    --model.ndim 3 \\\n    --model.nb_classes 2 \\\n    --data.batch_size 1 \\\n    --data.num_workers 2 \\\n    --trainer.max_epochs 1000 \\\n    --trainer.accelerator gpu \\\n    --trainer.devices 1 \\\n    --trainer.default_root_dir lightning_logs \\\n    --checkpoint.dirpath lightning_logs/checkpoints \\\n    --checkpoint.save_top_k 3 \\\n    --checkpoint.monitor eval_loss \\\n    --checkpoint.mode min","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T05:42:57.861073Z","iopub.execute_input":"2025-12-05T05:42:57.861409Z","iopub.status.idle":"2025-12-05T05:45:51.863880Z","shell.execute_reply.started":"2025-12-05T05:42:57.861382Z","shell.execute_reply":"2025-12-05T05:45:51.862974Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/lightning_fabric/utilities/seed.py:44: No seed found, seed set to 0\nSeed set to 0\nFound 85 subject folders. Scanning...\nSuccessfully loaded 57 pairs.\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n2025-12-05 05:43:05.378206: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764913385.400956     221 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764913385.407942     221 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name    | Type     | Params | Mode \n---------------------------------------------\n0 | network | SynthSeg | 1.6 M  | train\n---------------------------------------------\n1.6 M     Trainable params\n0         Non-trainable params\n1.6 M     Total params\n6.552     Total estimated model params size (MB)\n192       Modules in train mode\n0         Modules in eval mode\nSanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  return self._call_impl(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: DiceScore metric currently defaults to `average=micro`, but will change to`average=macro` in the v1.9 release. If you've explicitly set this parameter, you can ignore this warning.\n  warnings.warn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\nEpoch 0: 100%|███████| 16/16 [01:42<00:00,  0.16it/s, v_num=1, train_loss=0.362]\nValidation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\nValidation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\nValidation DataLoader 0:   0%|                            | 0/6 [00:00<?, ?it/s]\u001b[A\nValidation DataLoader 0:  17%|███▎                | 1/6 [00:09<00:49,  0.10it/s]\u001b[A\nValidation DataLoader 0:  33%|██████▋             | 2/6 [00:14<00:28,  0.14it/s]\u001b[A\nValidation DataLoader 0:  50%|██████████          | 3/6 [00:18<00:18,  0.16it/s]\u001b[A\nValidation DataLoader 0:  67%|█████████████▎      | 4/6 [00:23<00:11,  0.17it/s]\u001b[A\nValidation DataLoader 0:  83%|████████████████▋   | 5/6 [00:27<00:05,  0.18it/s]\u001b[A\nValidation DataLoader 0: 100%|████████████████████| 6/6 [00:32<00:00,  0.19it/s]\u001b[A\nEpoch 1:   0%| | 0/16 [00:00<?, ?it/s, v_num=1, train_loss=0.362, dice_real=5.69\u001b[A^C\n\nDetected KeyboardInterrupt, attempting graceful shutdown ...\n","output_type":"stream"}],"execution_count":12}]}