{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "445b22ea",
   "metadata": {
    "papermill": {
     "duration": 0.004221,
     "end_time": "2025-11-09T14:18:17.873964",
     "exception": false,
     "start_time": "2025-11-09T14:18:17.869743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e951f99",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-09T14:18:17.882423Z",
     "iopub.status.busy": "2025-11-09T14:18:17.882020Z",
     "iopub.status.idle": "2025-11-09T14:20:11.575412Z",
     "shell.execute_reply": "2025-11-09T14:20:11.574078Z"
    },
    "papermill": {
     "duration": 113.699935,
     "end_time": "2025-11-09T14:20:11.577304",
     "exception": false,
     "start_time": "2025-11-09T14:18:17.877369",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nnunetv2\r\n",
      "  Downloading nnunetv2-2.6.2.tar.gz (211 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.6.0+cu124)\r\n",
      "Collecting acvl-utils<0.3,>=0.2.3 (from nnunetv2)\r\n",
      "  Downloading acvl_utils-0.2.5.tar.gz (29 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting dynamic-network-architectures<0.5,>=0.4.1 (from nnunetv2)\r\n",
      "  Downloading dynamic_network_architectures-0.4.2.tar.gz (28 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (4.67.1)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.15.3)\r\n",
      "Collecting batchgenerators>=0.25.1 (from nnunetv2)\r\n",
      "  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.26.4)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.2.2)\r\n",
      "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.25.2)\r\n",
      "Requirement already satisfied: SimpleITK>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.5.2)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.2.3)\r\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.21)\r\n",
      "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2025.6.11)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.32.5)\r\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (5.3.2)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.7.2)\r\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.12.2)\r\n",
      "Collecting imagecodecs (from nnunetv2)\r\n",
      "  Downloading imagecodecs-2025.8.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (20 kB)\r\n",
      "Collecting yacs (from nnunetv2)\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\n",
      "Collecting batchgeneratorsv2>=0.3.0 (from nnunetv2)\r\n",
      "  Downloading batchgeneratorsv2-0.3.0.tar.gz (44 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.8.1)\r\n",
      "Requirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.6.1)\r\n",
      "Collecting connected-components-3d (from acvl-utils<0.3,>=0.2.3->nnunetv2)\r\n",
      "  Downloading connected_components_3d-3.26.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (32 kB)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (11.3.0)\r\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (1.0.0)\r\n",
      "Collecting unittest2 (from batchgenerators>=0.25.1->nnunetv2)\r\n",
      "  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (3.6.0)\r\n",
      "Collecting fft-conv-pytorch (from batchgeneratorsv2>=0.3.0->nnunetv2)\r\n",
      "  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.10.0)\r\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.1.2)\r\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (4.5.0)\r\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (2.11.0)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (9.0.0)\r\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (1.0.19)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->nnunetv2) (2.4.1)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (3.5)\r\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (2.37.0)\r\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (25.0)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (0.4)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (4.15.0)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2025.10.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.2->nnunetv2)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.2->nnunetv2)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.2->nnunetv2)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.2->nnunetv2)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.2->nnunetv2)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.2->nnunetv2)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.2->nnunetv2) (1.3.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.4.8)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (2.9.0.post0)\r\n",
      "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->nnunetv2) (6.5.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2025.10.5)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2) (1.5.2)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2) (6.0.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.2->nnunetv2) (3.0.3)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->nnunetv2) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->nnunetv2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->nnunetv2) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->nnunetv2) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24->nnunetv2) (2024.2.0)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (0.36.0)\r\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (0.5.3)\r\n",
      "Collecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2)\r\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting traceback2 (from unittest2->batchgenerators>=0.25.1->nnunetv2)\r\n",
      "  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24->nnunetv2) (2024.2.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2) (1.2.0)\r\n",
      "Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2)\r\n",
      "  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading imagecodecs-2025.8.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (26.4 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Downloading connected_components_3d-3.26.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\r\n",
      "Downloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\r\n",
      "Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\r\n",
      "Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\r\n",
      "Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, batchgeneratorsv2, dynamic-network-architectures\r\n",
      "  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for nnunetv2: filename=nnunetv2-2.6.2-py3-none-any.whl size=285890 sha256=eb5f259ed03de1987a07b34c1027a78f414248fba16227aabf2322df46d63466\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/99/ec/d2/0fb1be0015c40f2dc99535af585e41e876dd2b369039d9385b\r\n",
      "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for acvl-utils: filename=acvl_utils-0.2.5-py3-none-any.whl size=27213 sha256=31db0a8a20c2b48141d20a716b9a293b263c9bba14899766134becffa5a03901\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/8c/10/dcba79e0b2d1d463605233cec1fc6cfad47af5230b8985e464\r\n",
      "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for batchgenerators: filename=batchgenerators-0.25.1-py3-none-any.whl size=93088 sha256=44cb10a806eca440701d9f3a591cfeb28248b6c0c938b518929889d6e9791431\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/11/c7/fadca30e054c602093ffe36ba8a2f0a87dd2f86ac75191d3ed\r\n",
      "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.3.0-py3-none-any.whl size=65215 sha256=d6562ae11fda92c110b17bc21856eb56bbaa5d07ec99352ff8f840e79a326e0f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/c1/8f/94ca60255dbbadf27e1da4885002a6943c95b067b8e2dd39ea\r\n",
      "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.4.2-py3-none-any.whl size=39025 sha256=960c6d3a05c51efc922756e33098172576b59a5b11b2317628a933c30aa8f347\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/07/a9/c3/fcdf69ef4481860db91d0dc2466f63df8c3933262424a23f54\r\n",
      "Successfully built nnunetv2 acvl-utils batchgenerators batchgeneratorsv2 dynamic-network-architectures\r\n",
      "Installing collected packages: linecache2, argparse, yacs, traceback2, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, unittest2, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, fft-conv-pytorch, connected-components-3d, batchgenerators, imagecodecs, dynamic-network-architectures, batchgeneratorsv2, acvl-utils, nnunetv2\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed acvl-utils-0.2.5 argparse-1.4.0 batchgenerators-0.25.1 batchgeneratorsv2-0.3.0 connected-components-3d-3.26.1 dynamic-network-architectures-0.4.2 fft-conv-pytorch-1.2.0 imagecodecs-2025.8.2 linecache2-1.0.0 nnunetv2-2.6.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import glob\n",
    "\n",
    "!pip install nnunetv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6884461",
   "metadata": {
    "papermill": {
     "duration": 0.036401,
     "end_time": "2025-11-09T14:20:11.649544",
     "exception": false,
     "start_time": "2025-11-09T14:20:11.613143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Environment Setup and Directory Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc8c05",
   "metadata": {
    "papermill": {
     "duration": 0.035119,
     "end_time": "2025-11-09T14:20:11.721251",
     "exception": false,
     "start_time": "2025-11-09T14:20:11.686132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## clear previous folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bda72c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:20:11.796136Z",
     "iopub.status.busy": "2025-11-09T14:20:11.794392Z",
     "iopub.status.idle": "2025-11-09T14:20:11.802760Z",
     "shell.execute_reply": "2025-11-09T14:20:11.801445Z"
    },
    "papermill": {
     "duration": 0.048147,
     "end_time": "2025-11-09T14:20:11.805135",
     "exception": false,
     "start_time": "2025-11-09T14:20:11.756988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All previous nnUNet folders cleared.\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "\n",
    "# Paths used by nnUNet\n",
    "paths_to_clear = [\n",
    "    \"/kaggle/working/nnUNet_raw_data_base\",\n",
    "    \"/kaggle/working/nnUNet_preprocessed\",\n",
    "    \"/kaggle/working/nnUNet_results\"\n",
    "]\n",
    "\n",
    "for p in paths_to_clear:\n",
    "    if os.path.exists(p):\n",
    "        print(f\"ğŸ—‘ï¸ Removing {p} ...\")\n",
    "        shutil.rmtree(p)\n",
    "print(\"âœ… All previous nnUNet folders cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c718b005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:20:11.883331Z",
     "iopub.status.busy": "2025-11-09T14:20:11.883000Z",
     "iopub.status.idle": "2025-11-09T14:20:12.022012Z",
     "shell.execute_reply": "2025-11-09T14:20:12.020693Z"
    },
    "papermill": {
     "duration": 0.177382,
     "end_time": "2025-11-09T14:20:12.024443",
     "exception": false,
     "start_time": "2025-11-09T14:20:11.847061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet environment setup complete.\n"
     ]
    }
   ],
   "source": [
    "os.environ['nnUNet_raw_data_base'] = '/kaggle/working/nnUNet_raw_data_base'\n",
    "\n",
    "# Create necessary directories\n",
    "!mkdir -p $nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR\n",
    "\n",
    "print(\"nnUNet environment setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e6c8d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:20:12.099401Z",
     "iopub.status.busy": "2025-11-09T14:20:12.099015Z",
     "iopub.status.idle": "2025-11-09T14:20:12.109932Z",
     "shell.execute_reply": "2025-11-09T14:20:12.109103Z"
    },
    "papermill": {
     "duration": 0.05056,
     "end_time": "2025-11-09T14:20:12.111602",
     "exception": false,
     "start_time": "2025-11-09T14:20:12.061042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing files in the root of your uploaded metadata dataset (/kaggle/input/participants-data):\n",
      "['participants.tsv', 'participants.xlsx']\n"
     ]
    }
   ],
   "source": [
    "UPLOADED_DATASET_NAME = 'participants-data' \n",
    "CSV_DATASET_ROOT = f'/kaggle/input/{UPLOADED_DATASET_NAME}'\n",
    "\n",
    "print(f\"Listing files in the root of your uploaded metadata dataset ({CSV_DATASET_ROOT}):\")\n",
    "if os.path.exists(CSV_DATASET_ROOT):\n",
    "    # This will print the actual file name (e.g., ['participants.csv'] or ['participants.xlsx'])\n",
    "    print(os.listdir(CSV_DATASET_ROOT))\n",
    "else:\n",
    "    print(f\"Error: The dataset root {CSV_DATASET_ROOT} was not found. Please verify the uploaded dataset name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2480e8",
   "metadata": {
    "papermill": {
     "duration": 0.037691,
     "end_time": "2025-11-09T14:20:12.185368",
     "exception": false,
     "start_time": "2025-11-09T14:20:12.147677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Conversion and dataset.json Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1fc919a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:20:12.268351Z",
     "iopub.status.busy": "2025-11-09T14:20:12.268008Z",
     "iopub.status.idle": "2025-11-09T14:20:38.283234Z",
     "shell.execute_reply": "2025-11-09T14:20:38.282140Z"
    },
    "papermill": {
     "duration": 26.053735,
     "end_time": "2025-11-09T14:20:38.284762",
     "exception": false,
     "start_time": "2025-11-09T14:20:12.231027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read Excel file from: /kaggle/input/participants-data/participants.xlsx\n",
      "Available sheets: ['Sheet1']\n",
      "Total FCD subjects for TRAINING: 57\n",
      "Total FCD subjects for TESTING: 28\n",
      "\n",
      "--- Processing Training Subjects ---\n",
      "\n",
      "--- Processing Test Subjects ---\n",
      "\n",
      "âœ… Conversion complete!\n",
      "  Training subjects: 57\n",
      "  Test subjects: 28\n"
     ]
    }
   ],
   "source": [
    "# --- ğŸ¯ FINAL PATHS AND NAMES ğŸ¯ ---\n",
    "BASE_DIR = '/kaggle/input/organized-bonn-fcd-ii-epilepsy-mri-dataset/bonn_fcd_fixed' \n",
    "UPLOADED_DATASET_NAME = 'participants-data' \n",
    "EXCEL_FILE_NAME = 'participants.xlsx' \n",
    "EXCEL_PATH = os.path.join('/kaggle/input', UPLOADED_DATASET_NAME, EXCEL_FILE_NAME)\n",
    "# ---------------------------------------------\n",
    "\n",
    "TASK_ID = 2\n",
    "TASK_NAME = 'Dataset002_BonnFCD_FLAIR' \n",
    "NNUNET_RAW_DATA_DIR = os.path.join(os.environ['nnUNet_raw_data_base'], 'nnUNet_raw', TASK_NAME) \n",
    "\n",
    "# Create target directories\n",
    "# Create target directories\n",
    "IMAGES_TR_DIR = os.path.join(NNUNET_RAW_DATA_DIR, 'imagesTr')\n",
    "LABELS_TR_DIR = os.path.join(NNUNET_RAW_DATA_DIR, 'labelsTr')\n",
    "IMAGES_TS_DIR = os.path.join(NNUNET_RAW_DATA_DIR, 'imagesTs')\n",
    "LABELS_TS_DIR = os.path.join(NNUNET_RAW_DATA_DIR, 'labelsTs')  # optional test labels\n",
    "\n",
    "# Create them if missing\n",
    "for d in [IMAGES_TR_DIR, LABELS_TR_DIR, IMAGES_TS_DIR, LABELS_TS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# --- 1. Load and Filter the Excel Data ---\n",
    "print(f\"Attempting to read Excel file from: {EXCEL_PATH}\")\n",
    "\n",
    "try:\n",
    "    participants_df = pd.read_excel(EXCEL_PATH, sheet_name='participants')\n",
    "except ValueError:\n",
    "    xls = pd.ExcelFile(EXCEL_PATH)\n",
    "    print(f\"Available sheets: {xls.sheet_names}\")\n",
    "    participants_df = pd.read_excel(xls, sheet_name=xls.sheet_names[0])\n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR: Could not read Excel file. Please verify the EXCEL_PATH: {EXCEL_PATH}. Error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Ensure required columns exist\n",
    "required_columns = {'participant_id', 'group', 'split'}\n",
    "missing_columns = required_columns - set(participants_df.columns)\n",
    "if missing_columns:\n",
    "    raise Exception(f\"Missing required columns in Excel file: {missing_columns}\")\n",
    "\n",
    "# Filter FCD subjects for training and testing\n",
    "train_fcd_subjects = participants_df[\n",
    "    (participants_df['group'].str.lower() == 'fcd') & \n",
    "    (participants_df['split'].str.lower() == 'train')\n",
    "]['participant_id'].tolist()\n",
    "\n",
    "test_fcd_subjects = participants_df[\n",
    "    (participants_df['group'].str.lower() == 'fcd') & \n",
    "    (participants_df['split'].str.lower() == 'test')\n",
    "]['participant_id'].tolist()\n",
    "\n",
    "print(f\"Total FCD subjects for TRAINING: {len(train_fcd_subjects)}\")\n",
    "print(f\"Total FCD subjects for TESTING: {len(test_fcd_subjects)}\")\n",
    "\n",
    "training_files = []\n",
    "test_files = []\n",
    "skipped_subjects = []\n",
    "\n",
    "# --- Helper Function to Process Subjects ---\n",
    "def process_subject(subject_id, target_images_dir, is_training=True):\n",
    "    subject_path_with_anat = os.path.join(BASE_DIR, subject_id, 'anat')\n",
    "    \n",
    "    if not os.path.exists(subject_path_with_anat):\n",
    "        return False, f\"'anat' folder missing\"\n",
    "\n",
    "    # Look for relevant MRI and label files\n",
    "    # Look for relevant FLAIR and ROI files only\n",
    "    flair_search_pattern = os.path.join(subject_path_with_anat, f'{subject_id}*_FLAIR.nii')\n",
    "    label_search_pattern = os.path.join(subject_path_with_anat, f'{subject_id}*_FLAIR_roi.nii')\n",
    "    \n",
    "    flair_files = glob.glob(flair_search_pattern)\n",
    "    label_files = glob.glob(label_search_pattern)\n",
    "    \n",
    "    # Validation checks\n",
    "    if len(flair_files) != 1:\n",
    "        return False, f\"Missing or ambiguous FLAIR (found {len(flair_files)}).\"\n",
    "    \n",
    "    if is_training and len(label_files) != 1:\n",
    "        return False, f\"Training subject missing label file (found {len(label_files)}).\"\n",
    "\n",
    "    # Prepare target filenames\n",
    "    flair_target_name = f'{subject_id}_0000.nii'  # FLAIR only\n",
    "    label_target_name = f'{subject_id}.nii'\n",
    "    \n",
    "    try:\n",
    "        # Copy MRI modalities\n",
    "        shutil.copy(flair_files[0], os.path.join(target_images_dir, flair_target_name))\n",
    "\n",
    "        if is_training:\n",
    "            shutil.copy(label_files[0], os.path.join(LABELS_TR_DIR, label_target_name))\n",
    "            return True, {\"image\": f\"./imagesTr/{subject_id}\", \"label\": f\"./labelsTr/{subject_id}.nii\"}\n",
    "        else:\n",
    "            return True, {\"image\": f\"./imagesTs/{subject_id}\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        return False, f\"Copy error: {e}\"\n",
    "\n",
    "# --- 2. Process Training and Test Subjects ---\n",
    "print(\"\\n--- Processing Training Subjects ---\")\n",
    "for subject_id in train_fcd_subjects:\n",
    "    success, result = process_subject(subject_id, IMAGES_TR_DIR, is_training=True)\n",
    "    if success:\n",
    "        training_files.append(result)\n",
    "    else:\n",
    "        skipped_subjects.append((subject_id, f\"TRAIN - {result}\"))\n",
    "\n",
    "print(\"\\n--- Processing Test Subjects ---\")\n",
    "for subject_id in test_fcd_subjects:\n",
    "    success, result = process_subject(subject_id, IMAGES_TS_DIR, is_training=False)\n",
    "    if success:\n",
    "        test_files.append(result)\n",
    "\n",
    "    else:\n",
    "        skipped_subjects.append((subject_id, f\"TEST - {result}\"))\n",
    "\n",
    "# --- 3. Generate dataset.json ---\n",
    "dataset_json = {\n",
    "    \"name\": \"FCD Lesion Segmentation\",\n",
    "    \"description\": \"Focal Cortical Dysplasia Lesion Segmentation Dataset (Pre-defined Splits)\",\n",
    "    \"reference\": \"your/publication/link/here\",\n",
    "    \"licence\": \"CC-BY-4.0\",\n",
    "    \"release\": \"1.0\",\n",
    "    \"channel_names\": {\n",
    "    \"0\": \"FLAIR\"\n",
    "    },\n",
    "    \"labels\": {\n",
    "        \"background\": 0,\n",
    "        \"lesion\": 1\n",
    "    },\n",
    "    \"numTraining\": len(training_files),\n",
    "    \"file_ending\": \".nii\",\n",
    "    \"training\": training_files,\n",
    "    \"test\": test_files\n",
    "}\n",
    "\n",
    "# Save JSON\n",
    "with open(os.path.join(NNUNET_RAW_DATA_DIR, 'dataset.json'), 'w') as f:\n",
    "    json.dump(dataset_json, f, indent=4)\n",
    "\n",
    "print(f\"\\nâœ… Conversion complete!\")\n",
    "print(f\"  Training subjects: {len(training_files)}\")\n",
    "print(f\"  Test subjects: {len(test_files)}\")\n",
    "\n",
    "if skipped_subjects:\n",
    "    print(\"\\n--- âš ï¸ Skipped Subjects Summary ---\")\n",
    "    for subj, reason in skipped_subjects:\n",
    "        print(f\"  {subj}: {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0db8d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:20:38.357638Z",
     "iopub.status.busy": "2025-11-09T14:20:38.357176Z",
     "iopub.status.idle": "2025-11-09T14:20:41.198928Z",
     "shell.execute_reply": "2025-11-09T14:20:41.198015Z"
    },
    "papermill": {
     "duration": 2.880161,
     "end_time": "2025-11-09T14:20:41.200556",
     "exception": false,
     "start_time": "2025-11-09T14:20:38.320395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Copied label for test subject sub-00043\n",
      "âœ… Copied label for test subject sub-00066\n",
      "âœ… Copied label for test subject sub-00048\n",
      "âœ… Copied label for test subject sub-00064\n",
      "âœ… Copied label for test subject sub-00061\n",
      "âœ… Copied label for test subject sub-00092\n",
      "âœ… Copied label for test subject sub-00099\n",
      "âœ… Copied label for test subject sub-00032\n",
      "âœ… Copied label for test subject sub-00121\n",
      "âœ… Copied label for test subject sub-00136\n",
      "âœ… Copied label for test subject sub-00125\n",
      "âœ… Copied label for test subject sub-00134\n",
      "âœ… Copied label for test subject sub-00006\n",
      "âœ… Copied label for test subject sub-00144\n",
      "âœ… Copied label for test subject sub-00020\n",
      "âœ… Copied label for test subject sub-00142\n",
      "âœ… Copied label for test subject sub-00107\n",
      "âœ… Copied label for test subject sub-00074\n",
      "âœ… Copied label for test subject sub-00128\n",
      "âœ… Copied label for test subject sub-00108\n",
      "âœ… Copied label for test subject sub-00009\n",
      "âœ… Copied label for test subject sub-00004\n",
      "âœ… Copied label for test subject sub-00095\n",
      "âœ… Copied label for test subject sub-00034\n",
      "âœ… Copied label for test subject sub-00103\n",
      "âœ… Copied label for test subject sub-00145\n",
      "âœ… Copied label for test subject sub-00062\n",
      "âœ… Copied label for test subject sub-00100\n"
     ]
    }
   ],
   "source": [
    "# --- Copy test labels if available (optional evaluation) ---\n",
    "LABELS_TS_DIR = os.path.join(NNUNET_RAW_DATA_DIR, 'labelsTs')\n",
    "os.makedirs(LABELS_TS_DIR, exist_ok=True)\n",
    "\n",
    "for subject_id in test_fcd_subjects:\n",
    "    anat_folder = os.path.join(BASE_DIR, subject_id, 'anat')\n",
    "    label_search_pattern = os.path.join(anat_folder, f'{subject_id}*_FLAIR_roi.nii')\n",
    "    label_files = glob.glob(label_search_pattern)\n",
    "    \n",
    "    if label_files:\n",
    "        shutil.copy(label_files[0], os.path.join(LABELS_TS_DIR, f'{subject_id}.nii'))\n",
    "        print(f\"âœ… Copied label for test subject {subject_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6254301",
   "metadata": {
    "papermill": {
     "duration": 0.03642,
     "end_time": "2025-11-09T14:20:41.274277",
     "exception": false,
     "start_time": "2025-11-09T14:20:41.237857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21183d",
   "metadata": {
    "papermill": {
     "duration": 0.036398,
     "end_time": "2025-11-09T14:20:41.347039",
     "exception": false,
     "start_time": "2025-11-09T14:20:41.310641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Set nnU-Net environment paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de6e6909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:20:41.420503Z",
     "iopub.status.busy": "2025-11-09T14:20:41.419561Z",
     "iopub.status.idle": "2025-11-09T14:20:41.425529Z",
     "shell.execute_reply": "2025-11-09T14:20:41.424300Z"
    },
    "papermill": {
     "duration": 0.044674,
     "end_time": "2025-11-09T14:20:41.427255",
     "exception": false,
     "start_time": "2025-11-09T14:20:41.382581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… nnU-Net environment variables set\n",
      "RAW: /kaggle/working/nnUNet_raw_data_base/nnUNet_raw\n"
     ]
    }
   ],
   "source": [
    "import os, subprocess\n",
    "\n",
    "# Set environment variables for nnU-Net\n",
    "os.environ[\"nnUNet_raw\"] = \"/kaggle/working/nnUNet_raw_data_base/nnUNet_raw\"\n",
    "os.environ[\"nnUNet_preprocessed\"] = \"/kaggle/working/nnUNet_preprocessed\"\n",
    "os.environ[\"nnUNet_results\"] = \"/kaggle/working/nnUNet_results\"\n",
    "\n",
    "print(\"âœ… nnU-Net environment variables set\")\n",
    "print(\"RAW:\", os.environ[\"nnUNet_raw\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b18324",
   "metadata": {
    "papermill": {
     "duration": 0.036772,
     "end_time": "2025-11-09T14:20:41.500484",
     "exception": false,
     "start_time": "2025-11-09T14:20:41.463712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Verify dataset integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8d9dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:20:41.574664Z",
     "iopub.status.busy": "2025-11-09T14:20:41.574319Z",
     "iopub.status.idle": "2025-11-09T14:30:21.453903Z",
     "shell.execute_reply": "2025-11-09T14:30:21.452517Z"
    },
    "papermill": {
     "duration": 579.918945,
     "end_time": "2025-11-09T14:30:21.455910",
     "exception": false,
     "start_time": "2025-11-09T14:20:41.536965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Verifying dataset structure for Dataset002_BonnFCD_FLAIR...\n",
      "Fingerprint extraction...\n",
      "Dataset002_BonnFCD_FLAIR\n",
      "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIO'> as reader/writer\n",
      "WARNING: Affine is not the same for image and seg! \n",
      "Affine image: [[ 9.94139194e-01  5.02954759e-02  9.56572741e-02 -1.05817863e+02]\n",
      " [-5.00640646e-02  9.98734355e-01 -4.81724599e-03 -9.16165466e+01]\n",
      " [-9.57781449e-02  2.11276010e-08  9.95402634e-01 -9.58630219e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]] \n",
      "Affine seg: [[ 9.94142830e-01  5.02954759e-02  9.56572741e-02 -1.05818451e+02]\n",
      " [-5.00642471e-02  9.98734355e-01 -4.81724599e-03 -9.16165161e+01]\n",
      " [-9.57784951e-02  0.00000000e+00  9.95402634e-01 -9.58629761e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Image files: ['/kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/imagesTr/sub-00116_0000.nii']. \n",
      "Seg file: /kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/labelsTr/sub-00116.nii.\n",
      "This can be a problem but doesn't have to be. Please run nnUNetv2_plot_overlay_pngs to verify if everything is OK!\n",
      "\n",
      "WARNING: Affine is not the same for image and seg! \n",
      "Affine image: [[ 9.99946535e-01 -9.62814782e-03  1.78279402e-03 -7.47807159e+01]\n",
      " [ 9.78809595e-03  9.77891088e-01 -2.08885565e-01 -8.45367432e+01]\n",
      " [ 2.67801282e-04  2.08893001e-01  9.77938473e-01 -1.58331451e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]] \n",
      "Affine seg: [[ 9.99952018e-01 -9.62814782e-03  1.78279402e-03 -7.47815857e+01]\n",
      " [ 9.78814997e-03  9.77891088e-01 -2.08885565e-01 -8.45367584e+01]\n",
      " [ 2.67802738e-04  2.08893001e-01  9.77938473e-01 -1.58331451e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Image files: ['/kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/imagesTr/sub-00087_0000.nii']. \n",
      "Seg file: /kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/labelsTr/sub-00087.nii.\n",
      "This can be a problem but doesn't have to be. Please run nnUNetv2_plot_overlay_pngs to verify if everything is OK!\n",
      "\n",
      "WARNING: Affine is not the same for image and seg! \n",
      "Affine image: [[ 9.90562558e-01  1.17849894e-01 -6.99004978e-02 -8.58387833e+01]\n",
      " [-1.13116346e-01  9.91238236e-01  6.82002679e-02 -1.12392395e+02]\n",
      " [ 7.73250014e-02 -5.96500784e-02  9.95219886e-01 -1.26553299e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]] \n",
      "Affine seg: [[ 9.90568161e-01  1.17849894e-01 -6.99004978e-02 -8.58396606e+01]\n",
      " [-1.13116987e-01  9.91238236e-01  6.82002679e-02 -1.12392296e+02]\n",
      " [ 7.73254409e-02 -5.96500784e-02  9.95219886e-01 -1.26553360e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Image files: ['/kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/imagesTr/sub-00044_0000.nii']. \n",
      "Seg file: /kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/labelsTr/sub-00044.nii.\n",
      "This can be a problem but doesn't have to be. Please run nnUNetv2_plot_overlay_pngs to verify if everything is OK!\n",
      "\n",
      "WARNING: Affine is not the same for image and seg! \n",
      "Affine image: [[ 9.95483339e-01 -8.68931338e-02  3.81100662e-02 -7.96959991e+01]\n",
      " [ 7.17486963e-02  9.52208221e-01  2.96903253e-01 -1.19123627e+02]\n",
      " [-6.20872565e-02 -2.92829394e-01  9.54146802e-01 -8.42889404e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]] \n",
      "Affine seg: [[ 9.95488465e-01 -8.68931338e-02  3.81100662e-02 -7.96968079e+01]\n",
      " [ 7.17490613e-02  9.52208221e-01  2.96903253e-01 -1.19123688e+02]\n",
      " [-6.20875731e-02 -2.92829394e-01  9.54146802e-01 -8.42888718e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Image files: ['/kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/imagesTr/sub-00122_0000.nii']. \n",
      "Seg file: /kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/labelsTr/sub-00122.nii.\n",
      "This can be a problem but doesn't have to be. Please run nnUNetv2_plot_overlay_pngs to verify if everything is OK!\n",
      "\n",
      "WARNING: Affine is not the same for image and seg! \n",
      "Affine image: [[ 9.98092175e-01 -4.68831211e-02  4.02986854e-02 -7.50052185e+01]\n",
      " [ 5.06530777e-02  9.93869662e-01 -9.82717797e-02 -9.56718750e+01]\n",
      " [-3.54445316e-02  1.00125045e-01  9.94343340e-01 -1.20448334e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]] \n",
      "Affine seg: [[ 9.98087168e-01 -4.68831211e-02  4.02986854e-02 -7.50044327e+01]\n",
      " [ 5.06528243e-02  9.93869662e-01 -9.82717797e-02 -9.56718216e+01]\n",
      " [-3.54443528e-02  1.00125045e-01  9.94343340e-01 -1.20448364e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Image files: ['/kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/imagesTr/sub-00101_0000.nii']. \n",
      "Seg file: /kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/labelsTr/sub-00101.nii.\n",
      "This can be a problem but doesn't have to be. Please run nnUNetv2_plot_overlay_pngs to verify if everything is OK!\n",
      "\n",
      "WARNING: Affine is not the same for image and seg! \n",
      "Affine image: [[ 9.98671770e-01 -8.91311280e-03 -5.08703738e-02 -7.12747803e+01]\n",
      " [ 3.27690342e-03  9.93945956e-01 -1.09821133e-01 -8.83792572e+01]\n",
      " [ 5.15415780e-02  1.09507881e-01  9.92648721e-01 -1.52993759e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]] \n",
      "Affine seg: [[ 9.98665452e-01 -8.91311280e-03 -5.08703738e-02 -7.12737808e+01]\n",
      " [ 3.27688269e-03  9.93945956e-01 -1.09821133e-01 -8.83792648e+01]\n",
      " [ 5.15412539e-02  1.09507881e-01  9.92648721e-01 -1.52993698e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Image files: ['/kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/imagesTr/sub-00063_0000.nii']. \n",
      "Seg file: /kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/labelsTr/sub-00063.nii.\n",
      "This can be a problem but doesn't have to be. Please run nnUNetv2_plot_overlay_pngs to verify if everything is OK!\n",
      "\n",
      "WARNING: Affine is not the same for image and seg! \n",
      "Affine image: [[ 9.99526858e-01  1.83325633e-02  2.44736280e-02 -8.33606949e+01]\n",
      " [-2.64447518e-02  9.20082271e-01  3.90831470e-01 -1.16030701e+02]\n",
      " [-1.53527260e-02 -3.91295910e-01  9.20136869e-01 -6.50684509e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]] \n",
      "Affine seg: [[ 9.99532342e-01  1.83325633e-02  2.44736280e-02 -8.33615646e+01]\n",
      " [-2.64448971e-02  9.20082271e-01  3.90831470e-01 -1.16030685e+02]\n",
      " [-1.53528098e-02 -3.91295910e-01  9.20136869e-01 -6.50684433e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Image files: ['/kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/imagesTr/sub-00090_0000.nii']. \n",
      "Seg file: /kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/labelsTr/sub-00090.nii.\n",
      "This can be a problem but doesn't have to be. Please run nnUNetv2_plot_overlay_pngs to verify if everything is OK!\n",
      "\n",
      "WARNING: Affine is not the same for image and seg! \n",
      "Affine image: [[ 9.99748349e-01  8.61190725e-03  2.06066687e-02 -8.86936569e+01]\n",
      " [-8.61005951e-03  9.99962926e-01 -1.77450638e-04 -8.83382721e+01]\n",
      " [-2.06073876e-02 -1.86704305e-08  9.99787629e-01 -1.12756729e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]] \n",
      "Affine seg: [[ 9.99750555e-01  8.61190725e-03  2.06066687e-02 -8.86940155e+01]\n",
      " [-8.61007813e-03  9.99962926e-01 -1.77450638e-04 -8.83382492e+01]\n",
      " [-2.06074324e-02  0.00000000e+00  9.99787629e-01 -1.12756729e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Image files: ['/kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/imagesTr/sub-00091_0000.nii']. \n",
      "Seg file: /kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset002_BonnFCD_FLAIR/labelsTr/sub-00091.nii.\n",
      "This can be a problem but doesn't have to be. Please run nnUNetv2_plot_overlay_pngs to verify if everything is OK!\n",
      "\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIO'> as reader/writer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [00:27<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment planning...\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.03 1.03 1.03]. \n",
      "Current patch size: (160, 160, 96). \n",
      "Current median shape: [247.57281553 247.57281553 155.33980583]\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [255. 255. 160.], 3d_lowres: [248, 248, 155]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 80, 'patch_size': (256, 160), 'median_image_size_in_voxels': array([255., 160.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIO'> as reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (160, 160, 96), 'median_image_size_in_voxels': array([255., 255., 160.]), 'spacing': array([1., 1., 1.]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 1)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to /kaggle/working/nnUNet_preprocessed/Dataset002_BonnFCD_FLAIR/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset002_BonnFCD_FLAIR\n",
      "Configuration: 2d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [04:35<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: 3d_fullres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [03:49<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: 3d_lowres...\n",
      "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset002_BonnFCD_FLAIR. Skipping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['nnUNetv2_plan_and_preprocess', '-d', '2', '--verify_dataset_integrity'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nğŸ” Verifying dataset structure for Dataset002_BonnFCD_FLAIR...\")\n",
    "verify_command = [\n",
    "    \"nnUNetv2_plan_and_preprocess\",\n",
    "    \"-d\", \"2\",  # Dataset002_\n",
    "    \"--verify_dataset_integrity\"\n",
    "]\n",
    "\n",
    "subprocess.run(verify_command, check=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c88ee",
   "metadata": {
    "papermill": {
     "duration": 0.045613,
     "end_time": "2025-11-09T14:30:21.547042",
     "exception": false,
     "start_time": "2025-11-09T14:30:21.501429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Run preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0bff578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:30:21.637626Z",
     "iopub.status.busy": "2025-11-09T14:30:21.637233Z",
     "iopub.status.idle": "2025-11-09T14:39:15.003036Z",
     "shell.execute_reply": "2025-11-09T14:39:15.001607Z"
    },
    "papermill": {
     "duration": 533.414401,
     "end_time": "2025-11-09T14:39:15.005810",
     "exception": false,
     "start_time": "2025-11-09T14:30:21.591409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš™ï¸ Starting preprocessing (this may take several minutes)...\n",
      "Fingerprint extraction...\n",
      "Dataset002_BonnFCD_FLAIR\n",
      "Experiment planning...\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.03 1.03 1.03]. \n",
      "Current patch size: (160, 160, 96). \n",
      "Current median shape: [247.57281553 247.57281553 155.33980583]\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [255. 255. 160.], 3d_lowres: [248, 248, 155]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 80, 'patch_size': (256, 160), 'median_image_size_in_voxels': array([255., 160.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIO'> as reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (160, 160, 96), 'median_image_size_in_voxels': array([255., 255., 160.]), 'spacing': array([1., 1., 1.]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 1)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to /kaggle/working/nnUNet_preprocessed/Dataset002_BonnFCD_FLAIR/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset002_BonnFCD_FLAIR\n",
      "Configuration: 2d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [04:48<00:00,  5.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: 3d_fullres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [03:52<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: 3d_lowres...\n",
      "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset002_BonnFCD_FLAIR. Skipping.\n",
      "\n",
      "âœ… Preprocessing complete!\n",
      "Preprocessed data stored in: /kaggle/working/nnUNet_preprocessed/Dataset002_BonnFCD_FLAIR/\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nâš™ï¸ Starting preprocessing (this may take several minutes)...\")\n",
    "\n",
    "preprocess_command = [\n",
    "    \"nnUNetv2_plan_and_preprocess\",\n",
    "    \"-d\", \"2\"\n",
    "]\n",
    "\n",
    "subprocess.run(preprocess_command, check=False)\n",
    "\n",
    "print(\"\\nâœ… Preprocessing complete!\")\n",
    "print(\"Preprocessed data stored in: /kaggle/working/nnUNet_preprocessed/Dataset002_BonnFCD_FLAIR/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41e6041a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:39:15.116446Z",
     "iopub.status.busy": "2025-11-09T14:39:15.116033Z",
     "iopub.status.idle": "2025-11-09T14:39:15.123057Z",
     "shell.execute_reply": "2025-11-09T14:39:15.122081Z"
    },
    "papermill": {
     "duration": 0.060093,
     "end_time": "2025-11-09T14:39:15.124644",
     "exception": false,
     "start_time": "2025-11-09T14:39:15.064551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Folder exists! Contents:\n",
      "['gt_segmentations', 'nnUNetPlans_3d_fullres', 'nnUNetPlans.json', 'dataset_fingerprint.json', 'dataset.json', 'nnUNetPlans_2d']\n"
     ]
    }
   ],
   "source": [
    "# 4. (Optional) Verify output paths\n",
    "import os\n",
    "\n",
    "pre_dir = \"/kaggle/working/nnUNet_preprocessed/Dataset002_BonnFCD_FLAIR\"\n",
    "if os.path.exists(pre_dir):\n",
    "    print(\"âœ… Folder exists! Contents:\")\n",
    "    print(os.listdir(pre_dir))\n",
    "else:\n",
    "    print(\"âŒ Preprocessed folder not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d927fa",
   "metadata": {
    "papermill": {
     "duration": 0.051775,
     "end_time": "2025-11-09T14:39:15.225781",
     "exception": false,
     "start_time": "2025-11-09T14:39:15.174006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8459864,
     "sourceId": 13340862,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8668032,
     "sourceId": 13636920,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1263.150748,
   "end_time": "2025-11-09T14:39:15.897228",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-09T14:18:12.746480",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
